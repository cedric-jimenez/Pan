# Cr√©ation d'un mod√®le YOLOv8 pour la d√©tection automatique de salamandres

## Contexte du projet

Ce document d√©crit la m√©thode utilis√©e pour cr√©er un mod√®le de d√©tection d'objets permettant de cropper automatiquement des salamandres tachet√©es (*Salamandra salamandra*) √† partir de photos de terrain.

**Objectif** : Automatiser l'extraction des salamandres depuis des photos nocturnes prises sur le terrain, afin de pr√©parer les donn√©es pour un syst√®me d'identification individuelle bas√© sur les motifs de taches.

**Dataset initial** :
- 157 photos de terrain annot√©es manuellement
- 472 images apr√®s augmentation de donn√©es (transformations Roboflow)
- Localisation : sessions de terrain multiples
- Contraintes : √©clairage variable, salamandres parfois boueuses, backgrounds naturels complexes

## M√©thodologie

### 1. Annotation des donn√©es (Roboflow)

**Outil utilis√©** : [Roboflow](https://roboflow.com)

**Process d'annotation** :
1. Upload des 157 photos sur Roboflow
2. Cr√©ation de bounding boxes autour de chaque salamandre
3. Labellisation avec une seule classe : `salamander`
4. Application des transformations automatiques

**Pourquoi Roboflow ?**
- Interface intuitive pour l'annotation rapide
- Gestion automatique du split train/validation/test
- Export direct au format YOLOv8
- Augmentation de donn√©es int√©gr√©e et configurable
- Versioning du dataset

### 2. Augmentation de donn√©es

**Transformations appliqu√©es** :
- **Rotation** : Variations angulaires pour simuler diff√©rents angles de prise de vue
- **Torsion** : D√©formations l√©g√®res pour am√©liorer la robustesse
- **Flip horizontal** : Miroir pour doubler les perspectives
- **Variations de luminosit√©** : Adaptation aux conditions nocturnes variables
- **Autres transformations Roboflow** : Selon configuration

**R√©sultat** : 157 images originales ‚Üí **472 images d'entra√Ænement**

**B√©n√©fices** :
- ‚úÖ Augmente artificiellement la taille du dataset (√ó3)
- ‚úÖ Am√©liore la g√©n√©ralisation du mod√®le
- ‚úÖ Compense les conditions de terrain variables
- ‚úÖ R√©duit le risque d'overfitting

### 3. Export du dataset

**Format** : YOLOv8 (YOLO format text annotations)

**Structure obtenue** :
```
dataset/
‚îú‚îÄ‚îÄ data.yaml          # Configuration du dataset
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/        # Images d'entra√Ænement
‚îÇ   ‚îî‚îÄ‚îÄ labels/        # Annotations au format YOLO (.txt)
‚îú‚îÄ‚îÄ valid/
‚îÇ   ‚îú‚îÄ‚îÄ images/        # Images de validation
‚îÇ   ‚îî‚îÄ‚îÄ labels/
‚îî‚îÄ‚îÄ test/              # (optionnel)
    ‚îú‚îÄ‚îÄ images/
    ‚îî‚îÄ‚îÄ labels/
```

**Fichier data.yaml** :
```yaml
path: /chemin/vers/dataset
train: train/images
val: valid/images

nc: 1                    # Nombre de classes
names: ['salamander']    # Nom de la classe
```

**Split automatique** : Train/Validation g√©r√© par Roboflow (typiquement 80/20)

### 4. Choix du mod√®le

**Mod√®le s√©lectionn√©** : **YOLOv8 Nano (`yolov8n.pt`)**

**Sp√©cifications YOLOv8n** :
- Param√®tres : ~3.2M
- Taille du mod√®le : ~6 MB
- Vitesse : Tr√®s rapide (excellente pour inf√©rence temps r√©el)
- Pr√©cision : Suffisante pour une seule classe bien d√©finie

**Justification** :
- ‚úÖ L√©ger et rapide ‚Üí id√©al pour d√©ploiement sur serveur sans GPU
- ‚úÖ Excellent pour la d√©tection d'objets de taille moyenne
- ‚úÖ Transfer learning depuis COCO dataset (80 classes)
- ‚úÖ Biblioth√®que Ultralytics tr√®s stable et document√©e
- ‚úÖ Facile √† d√©ployer en production (Railway, FastAPI)
- ‚úÖ Suffisant pour une t√¢che mono-classe simple

**Alternatives consid√©r√©es mais non retenues** :
- **YOLOv8s/m/l** : Plus lourds, gains marginaux pour ce cas d'usage mono-classe
- **YOLOv11** : Plus r√©cent mais pas n√©cessaire, YOLOv8 largement suffisant
- **Segmentation (YOLOv8-seg)** : Overkill, les bounding boxes suffisent pour le crop
- **Faster R-CNN** : Plus lent, trop complexe pour une seule classe

### 5. Environnement d'entra√Ænement

**Plateforme** : **Kaggle Notebooks**

**Justification** :
- ‚úÖ GPU gratuit (Tesla T4 ou P100)
- ‚úÖ Pas de configuration locale n√©cessaire
- ‚úÖ 30h/semaine de GPU gratuites
- ‚úÖ Stockage illimit√© pour les datasets
- ‚úÖ Notebooks reproductibles et partageables

**Configuration technique** :
- **GPU** : Tesla T4 (16 GB VRAM) ou P100
- **Python** : 3.10+
- **PyTorch** : 2.x + CUDA
- **Ultralytics** : 8.3.x

**Alternative** : Entra√Ænement local possible sur CPU (~2-4h pour 100 epochs) ou GPU NVIDIA

### 6. Installation et pr√©paration

**Installation de YOLOv8** :
```bash
pip install ultralytics
```

**V√©rification GPU** (dans Kaggle Notebook) :
```python
import torch
print(f"GPU disponible : {torch.cuda.is_available()}")
print(f"GPU : {torch.cuda.get_device_name(0)}")
```

**Upload du dataset sur Kaggle** :
1. Exporter le dataset depuis Roboflow (format YOLOv8)
2. Zipper le dataset localement
3. Cr√©er un nouveau dataset sur Kaggle
4. Uploader le fichier zip
5. Ajouter le dataset au notebook Kaggle

### 7. Configuration de l'entra√Ænement

**Code d'entra√Ænement** :
```python
from ultralytics import YOLO

# Charge le mod√®le pr√©-entra√Æn√©
model = YOLO('yolov8n.pt')

# Entra√Ænement
results = model.train(
    data='data.yaml',
    epochs=100,              # Nombre d'it√©rations
    imgsz=640,               # R√©solution des images (standard YOLO)
    batch=16,                # Taille du batch (adapter selon GPU)
    patience=20,             # Early stopping apr√®s 20 epochs sans am√©lioration
    device=0,                # GPU (ou 'cpu' pour CPU)

    # Augmentation de donn√©es (en plus de Roboflow)
    hsv_h=0.015,             # Variation de teinte
    hsv_s=0.7,               # Variation de saturation
    hsv_v=0.4,               # Variation de luminosit√©
    degrees=10,              # Rotation ¬±10¬∞
    translate=0.1,           # Translation 10%
    scale=0.5,               # Zoom 50%
    flipud=0.0,              # Pas de flip vertical (salamandres toujours √† l'endroit)
    fliplr=0.5,              # Flip horizontal 50% du temps
    mosaic=1.0,              # Mosa√Øque (combine 4 images)

    # Sauvegardes
    save=True,
    save_period=10,          # Sauvegarde tous les 10 epochs
    plots=True,              # G√©n√®re les graphiques
    name='salamander_yolov8n'
)
```

**Justification des hyperparam√®tres** :

| Param√®tre | Valeur | Justification |
|-----------|--------|---------------|
| `epochs` | 100 | Suffisant avec early stopping |
| `batch` | 16-32 | Maximise l'utilisation du GPU T4 |
| `imgsz` | 640 | Standard YOLO, bon compromis vitesse/pr√©cision |
| `patience` | 20 | √âvite l'overfitting automatiquement |
| `flipud` | 0.0 | Salamandres toujours dans le bon sens |
| `fliplr` | 0.5 | Sym√©trie horizontale possible |
| `mosaic` | 1.0 | Augmente drastiquement la diversit√© |

### 8. Dur√©e d'entra√Ænement

**Sur GPU Tesla T4** : ~25-35 minutes pour 100 epochs

**Breakdown** :
- Pr√©paration des donn√©es : ~1-2 min
- Entra√Ænement : ~20-30 min (varie selon early stopping)
- Validation finale : ~2 min
- G√©n√©ration des graphiques : ~1 min

**Sur CPU** : ~2-4 heures pour 100 epochs (non recommand√©)

### 9. R√©sultats obtenus

**M√©triques finales** :

| M√©trique | Valeur | Interpr√©tation |
|----------|--------|----------------|
| **mAP50** | `TODO` | Pr√©cision √† IoU=0.50 |
| **mAP50-95** | `TODO` | Pr√©cision moyenne sur IoU 0.50-0.95 |
| **Precision** | `TODO` | % de d√©tections correctes |
| **Recall** | `TODO` | % de salamandres trouv√©es |

> **Note** : Remplacer les `TODO` avec les vraies valeurs du fichier `results.csv` g√©n√©r√© par YOLO

**Interpr√©tation typique pour un bon mod√®le** :
- ‚úÖ mAP50 > 0.90 : Excellent
- ‚úÖ Precision > 0.85 : Peu de faux positifs
- ‚úÖ Recall > 0.85 : D√©tecte la plupart des salamandres

**Vitesse d'inf√©rence** (estim√©e sur GPU T4) :
- Preprocessing : ~3-5ms
- Inf√©rence : ~5-10ms
- Postprocessing : ~3-5ms
- **Total : ~15-20ms par image** (50-60 FPS)

### 10. Validation qualitative

**Tests √† effectuer** :
- Valider sur des images du set de validation
- V√©rifier les bounding boxes visuellement
- Tester sur des conditions extr√™mes (tr√®s sombre, salamandre boueuse)
- V√©rifier l'absence de faux positifs

**Cas limites √† g√©rer** :
- ‚úÖ Salamandres partiellement cach√©es (feuilles, branches)
- ‚úÖ √âclairage tr√®s faible
- ‚úÖ Salamandres tr√®s boueuses (patterns peu visibles)
- ‚úÖ Backgrounds complexes (feuilles mortes, texture bois)
- ‚ö†Ô∏è Multiples salamandres dans une photo
- ‚ö†Ô∏è Salamandres tr√®s petites (loin de la cam√©ra)

### 11. Fichiers g√©n√©r√©s

**Apr√®s entra√Ænement, YOLO g√©n√®re** :

```
runs/detect/salamander_yolov8n/
‚îú‚îÄ‚îÄ weights/
‚îÇ   ‚îú‚îÄ‚îÄ best.pt              # Meilleur mod√®le (utiliser celui-ci)
‚îÇ   ‚îî‚îÄ‚îÄ last.pt              # Dernier epoch (backup)
‚îú‚îÄ‚îÄ results.csv              # M√©triques par epoch
‚îú‚îÄ‚îÄ results.png              # Graphiques de loss et m√©triques
‚îú‚îÄ‚îÄ confusion_matrix.png     # Matrice de confusion
‚îú‚îÄ‚îÄ PR_curve.png             # Courbe Precision-Recall
‚îú‚îÄ‚îÄ F1_curve.png             # Courbe F1-score
‚îú‚îÄ‚îÄ labels.jpg               # Distribution des annotations
‚îú‚îÄ‚îÄ train_batch*.jpg         # Exemples d'images d'entra√Ænement
‚îî‚îÄ‚îÄ val_batch*_pred.jpg      # Pr√©dictions sur validation
```

**Fichier principal √† sauvegarder** : `best.pt` (~6 MB)

### 12. Utilisation du mod√®le

#### Script Python de d√©tection basique
```python
from ultralytics import YOLO

# Charge le mod√®le entra√Æn√©
model = YOLO('best.pt')

# D√©tection sur une image
results = model('photo.jpg', conf=0.5)

# Affiche le r√©sultat avec bounding boxes
results[0].show()

# Sauvegarde l'image annot√©e
results[0].save('output.jpg')
```

#### Script de crop automatique centr√©
```python
from ultralytics import YOLO
import cv2
import numpy as np

model = YOLO('best.pt')
image_path = 'photo.jpg'

# D√©tection
results = model(image_path, conf=0.5)
image = cv2.imread(image_path)
height, width = image.shape[:2]

# Pour chaque salamandre d√©tect√©e
for i, box in enumerate(results[0].boxes):
    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
    confidence = float(box.conf[0])

    # Calcul du centre de la bounding box
    center_x = (x1 + x2) // 2
    center_y = (y1 + y2) // 2

    # Largeur et hauteur de la bbox
    bbox_width = x2 - x1
    bbox_height = y2 - y1

    # Crop carr√© centr√© avec marge de 20%
    margin = 1.2
    crop_size = int(max(bbox_width, bbox_height) * margin)

    # Coordonn√©es du crop centr√©
    crop_x1 = max(0, center_x - crop_size // 2)
    crop_y1 = max(0, center_y - crop_size // 2)
    crop_x2 = min(width, center_x + crop_size // 2)
    crop_y2 = min(height, center_y + crop_size // 2)

    # D√©coupe et sauvegarde
    crop = image[crop_y1:crop_y2, crop_x1:crop_x2]
    cv2.imwrite(f'salamander_{i+1}_conf{confidence:.2f}.jpg', crop)

    print(f"‚úì Salamandre {i+1} d√©tect√©e : confiance {confidence:.2%}")
```

#### Traitement par batch (dossier entier)
```python
from pathlib import Path

input_folder = Path('photos_terrain')
output_folder = Path('salamanders_cropped')
output_folder.mkdir(exist_ok=True)

for img_path in input_folder.glob('*.jpg'):
    results = model(str(img_path), conf=0.5)
    image = cv2.imread(str(img_path))

    if len(results[0].boxes) == 0:
        print(f"‚ö†Ô∏è  Aucune salamandre dans {img_path.name}")
        continue

    for i, box in enumerate(results[0].boxes):
        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())

        # Crop avec marge
        margin = 20
        crop = image[
            max(0, y1-margin):min(image.shape[0], y2+margin),
            max(0, x1-margin):min(image.shape[1], x2+margin)
        ]

        crop_name = f"{img_path.stem}_sal{i}.jpg"
        cv2.imwrite(str(output_folder / crop_name), crop)

    print(f"‚úì {img_path.name} : {len(results[0].boxes)} salamandre(s)")
```

## Points cl√©s de succ√®s

### Ce qui a bien fonctionn√©

1. **Roboflow pour l'annotation** : Interface rapide et intuitive
2. **Augmentation de donn√©es** : √ó3 le dataset (157 ‚Üí 472 images)
3. **YOLOv8 Nano** : L√©ger, rapide, suffisant pour une classe
4. **Transfer learning** : Partir d'un mod√®le pr√©-entra√Æn√© COCO
5. **Kaggle GPU** : Entra√Ænement gratuit et rapide (~30 min)
6. **Early stopping** : √âvite l'overfitting automatiquement

### Limitations actuelles

1. **Dataset mono-site** : Le mod√®le est optimis√© pour ces conditions de terrain
2. **Conditions nocturnes** : Performances sur photos diurnes non test√©es
3. **Une seule esp√®ce** : *Salamandra salamandra* uniquement
4. **Bounding boxes** : Pas de segmentation pixel-perfect
5. **Petit dataset** : 157 images originales (compens√© par augmentation)

### Am√©liorations futures possibles

1. **G√©n√©ralisation** : Ajouter des photos d'autres sites et conditions
2. **Multi-esp√®ces** : D√©tecter plusieurs esp√®ces d'amphibiens
3. **Segmentation** : Passer √† YOLOv8-seg pour masques pr√©cis
4. **Dataset plus large** : 500+ images originales pour robustesse
5. **Export ONNX** : Pour d√©ploiement optimis√© sur serveur CPU
6. **Fine-tuning** : R√©entra√Æner avec nouvelles donn√©es terrain

## Int√©gration dans le pipeline complet

### Architecture globale

```
üì∏ Photos terrain
    ‚Üì
üñºÔ∏è  Upload sur l'app web (Next.js / Vercel)
    ‚Üì
üêç Appel API Python (FastAPI / Railway)
    ‚Üì
ü§ñ YOLO D√©tection (best.pt)
    ‚Üì
‚úÇÔ∏è  Crop centr√© sur salamandre
    ‚Üì
üíæ Sauvegarde image cropp√©e
    ‚Üì
üîç [Future] Identification individuelle (r√©seau siamois)
    ‚Üì
üìä Base de donn√©es individus
```

### Prochaine √©tape : D√©ploiement

**Service FastAPI** (√† cr√©er dans `pan-py`) :
```python
from fastapi import FastAPI, UploadFile
from ultralytics import YOLO
import cv2
import numpy as np

app = FastAPI()
model = YOLO('best.pt')

@app.post("/crop-salamander")
async def crop_salamander(file: UploadFile):
    # Lire l'image
    contents = await file.read()
    nparr = np.frombuffer(contents, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # D√©tection YOLO
    results = model(img, conf=0.5)

    if len(results[0].boxes) == 0:
        return {"success": False, "message": "Aucune salamandre d√©tect√©e"}

    # Crop de la premi√®re salamandre d√©tect√©e
    box = results[0].boxes[0]
    x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())

    # ... logique de crop centr√© ...

    return {
        "success": True,
        "cropped_image": base64_encoded_image,
        "confidence": float(box.conf[0])
    }
```

## Ressources et r√©f√©rences

**Outils utilis√©s** :
- [Ultralytics YOLOv8](https://docs.ultralytics.com/) - Framework de d√©tection d'objets
- [Roboflow](https://roboflow.com/) - Annotation et augmentation de donn√©es
- [Kaggle Notebooks](https://www.kaggle.com/code) - Entra√Ænement GPU gratuit

**Documentation YOLO** :
- [YOLOv8 Training Guide](https://docs.ultralytics.com/modes/train/)
- [YOLOv8 Hyperparameters](https://docs.ultralytics.com/usage/cfg/)
- [YOLOv8 Export Formats](https://docs.ultralytics.com/modes/export/)

**Tutoriels recommand√©s** :
- [Train YOLOv8 on Custom Dataset](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/)
- [YOLO for Wildlife Monitoring](https://wildlife.ai/)

## Conclusion

L'entra√Ænement d'un mod√®le **YOLOv8 Nano** sur **472 images** (157 originales + augmentation) a produit un d√©tecteur de salamandres performant en environ **30 minutes** sur GPU Kaggle gratuit.

Cette approche d√©montre qu'avec :
- ‚úÖ Des annotations de qualit√© (Roboflow)
- ‚úÖ Un mod√®le adapt√© (YOLOv8n)
- ‚úÖ De l'augmentation de donn√©es (√ó3)
- ‚úÖ Du transfer learning (COCO)
- ‚úÖ Un dataset de taille raisonnable (~500 images)

Il est possible de cr√©er des outils de d√©tection d'objets tr√®s performants pour des applications de recherche en √©cologie, **m√™me avec des ressources limit√©es**.

Le mod√®le (`best.pt`, ~6 MB) est maintenant pr√™t √† √™tre d√©ploy√© dans un microservice Python (FastAPI) pour traiter automatiquement les photos upload√©es et extraire les salamandres individuelles.

---

**Auteur** : C√©dric Jimenez
**Date** : Janvier 2025
**Mod√®le** : YOLOv8 Nano
**Dataset** : 157 images ‚Üí 472 apr√®s augmentation
**Plateforme** : Kaggle (GPU T4)
**Dur√©e d'entra√Ænement** : ~30 minutes (100 epochs)
